{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t-UU0dWc63C"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "\n",
        "The sample text I used still had chapter names and a lot of blank spaces that had to be removed before finetuning the model."
      ],
      "metadata": {
        "id": "w1DiNSUPc8P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Sample_Folder/Sample_text.txt', 'r') as file:\n",
        "  sample = file.read()"
      ],
      "metadata": {
        "id": "I-Cwk-_jdAGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep / Data Cleaning"
      ],
      "metadata": {
        "id": "ZXlPo9rPfZWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_chapters(text):\n",
        "    # Find Chapter followed by space and one or more digit\n",
        "    pattern = re.compile(r'Chapter \\d+')\n",
        "\n",
        "    # Use sub() to replace matched patterns with an empty string\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "7c6SBvGKfYPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = remove_chapters(sample)\n",
        "\n",
        "# Remove newlines and carriage returns\n",
        "text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
        "\n",
        "# Remove any leading or trailing white spaces\n",
        "text = text.strip()\n",
        "\n",
        "# Convert all text to lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# Remove any punctuation\n",
        "text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Remove any extra whitespace\n",
        "text = ' '.join(text.split())\n",
        "\n",
        "# Remove any chapter headings, footnotes, or other non-story text\n",
        "# This step will depend on the specific structure of your text\n",
        "# You may need to manually remove these sections or use regular expressions to match and remove them\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "words_string= ' '.join(words)\n",
        "\n",
        "print(words_string[:20]) #to check results as you go, use index, don't try and print all words if it's a large document"
      ],
      "metadata": {
        "id": "L9vpOjryfwDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save new file in file path"
      ],
      "metadata": {
        "id": "4tHnds6Jjy30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/Sample_Folder/'\n",
        "\n",
        "name_of_file = \"TEXT_transformed\"\n",
        "\n",
        "completeName = os.path.join(save_path, name_of_file+\".txt\")\n",
        "\n",
        "toFile = words_string\n",
        "\n",
        "with open(completeName, \"wb\") as my_file:\n",
        "  my_file.write(toFile.encode('utf-8'))"
      ],
      "metadata": {
        "id": "9XM8IsT9ju2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get GTP model to finetune later on\n",
        "\n",
        "I used gtp-2-simple since it's the free version, but if you want a more accurate result, it might be worth comparing it to the paid model."
      ],
      "metadata": {
        "id": "AkKmDRKMj7h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt-2-simple"
      ],
      "metadata": {
        "id": "sdPuMmVnkGqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "gpt2.download_gpt2()\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "48sfydRnkJlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check if GPU is enables"
      ],
      "metadata": {
        "id": "9kTAj2N0kNYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "I8IeJcgIkSVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load pre-trained GPT-2 model"
      ],
      "metadata": {
        "id": "rwokRZV6kVLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained GPT-2 model\n",
        "model_name = \"124M\"\n",
        "gpt2.download_gpt2(model_name=model_name)\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "file_name = 'TEXT_transformed.txt'"
      ],
      "metadata": {
        "id": "umERjScMkUfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finetune model\n",
        "\n",
        "- Here we specify the name of the run. I like including the date\n",
        "- With save_every we can save the model after a specific number of sets\n",
        "- By default, the gpt2.finetune function saves the 5 most recent checkpoints and deletes older checkpoints to save disk space. You can change this behavior by setting the keep_checkpoint_max parameter to a different value.\n",
        "The advantage with having a name of the run, means we can reload the trained model and finetune it further once we get more data."
      ],
      "metadata": {
        "id": "besBgzk0krhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_run = '2xxxxx_sample_vxx'"
      ],
      "metadata": {
        "id": "Ae2Lm5NzlPh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name= name_run,\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=50\n",
        "              )"
      ],
      "metadata": {
        "id": "APH66IcXlaWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate text\n",
        "- temperature: Temperature is a hyperparameter that controls the randomness of the generated text. A higher temperature (e.g., 0.7) makes the output more random and creative, while a lower temperature (e.g., 0.2) makes the output more focused and deterministic.\n",
        "- return_as_list: if set to true it returns the text as a list of strings."
      ],
      "metadata": {
        "id": "jJqcE-y6otC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name=name_run) #load finetuned model\n",
        "gentext1 = gpt2.generate(sess, run_name=name_run) #generate from the trained model\n",
        "gentext2 = gpt2.generate(sess, length=1023, temperature= 0.7,  return_as_list=True, run_name= name_run) #generate from the trained model"
      ],
      "metadata": {
        "id": "sr1pEFKlou94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
